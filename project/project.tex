%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2015 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2015,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{amsfonts}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2015} with
% \usepackage[nohyperref]{icml2015} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}


% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage[accepted]{icml2015}

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2015}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2015}

\let\oldthebibliography=\thebibliography
  \let\endoldthebibliography=\endthebibliography
  \renewenvironment{thebibliography}[1]{%
    \begin{oldthebibliography}{#1}%
      \setlength{\parskip}{.3ex}%
      \setlength{\itemsep}{.3ex}%
  }%
  {%
    \end{oldthebibliography}%
  }
  
\begin{document} 
\twocolumn[
\icmltitle{CS 6780 Research Project: Multi-armed Bandits with Dependent Arms}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2015
% package.
\icmlauthor{Bangrui Chen}{bc496@cornell.edu}
\icmlauthor{Saul Toscano Palmerin}{st684@cornell.edu}
\icmlauthor{Zhengdi Shen}{zs267@cornell.edu}

% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{boring formatting information, machine learning, ICML}

\vskip 0.3in
]


\section{Motivation}
We are interested in the multi armed bandits problem with correlated arms. Theoretically this problem can be solved using dynamic programming, however it usually suffers from the curse of dimensionality when the dimension of the arm is high. There are two well known heuristic algorithms for this problem which are Exponential Gradient algorithm and the upper confidence bound algorithm. In this project, we hope to investigate the combination of these two different algorithms.


\section{Problem Formulation}
We have a finite set $\mathcal{U}_{r}=\{\bold{u}_{1},\cdots,\bold{u}_{m}\}\subset \mathbb{R}^{r}$ that corresponds to the set of arms, where $r\geq 2$. For any time $t=1,2,\cdots,T$, we are asked to pick one arm $X_{t}$. The reward $Y_{t}$ of playing arm $X_{t}\in \mathcal{U}_{r}$ in period t is given by
\begin{equation}
Y_{t} = \theta \cdot X_{t} + \epsilon_{t}, \nonumber
\end{equation}
where $\epsilon_{t}\sim N(0,\sigma^{2})$ is the measurement error with $\sigma$ known. Here $\theta$ is an unknown random vector, which is drawn from a multivariate normal distribution with mean $\mu$ and variance $\Sigma$. We further assume $\mu$ and $\Sigma$ are known.

For a fixed time period T, the goal of this problem is to find a strategy $\pi$ to maximize the following expression
\begin{equation}
E^{\pi}\left[\sum_{t=1}^{T} Y_{t}\right].
\end{equation}
Or equivalently, we are trying to find a policy that can minimize the Bayes risk under $\pi$:
\begin{equation}
\text{Risk}(T,\pi) = E\left[\text{Regret}(\theta,T,\pi)\right],
\end{equation}

where the cumulative regret is defined as the following:
\begin{equation}
\text{Regret}(\theta_{0},T,\pi)=\sum_{t=1}^{T}E\left[\max_{X\in \mathcal{U}_{r}}X\cdot\theta_{0}-X_{t}\cdot \theta_{0}|\theta=\theta_{0}\right].
\end{equation}





\section{PEGE}

PEGE algorithm
\begin{algorithm}
\caption{Phased Exploration and Greedy Exploitation}
\textbf{Description}: For each cycle $c\geq 1$, complete the following two phases:
\begin{itemize}
\item [1. ] \textbf{Exploration (r periods)} For $k=1,2,\cdots,r$, play arm 
\item [2. ] \textbf{Exploitation (c periods)}
\end{itemize}
\end{algorithm}


\section{Heuristic Algorithms}
There are two well known algorithms for this problem, which are Exponential Gradient algorithm and the upper confidence bound algorithm.\

\textbf{Notations: }

\begin{center}
\begin{tabular}{ll}
${x}_i$: & feature of the recommended restaurant at step $i$, binary vector\\
$y_i$: & rate given by the user at step $i$, range is $(0,5)$\\
${\theta}$: & user's preference\\
${\mu_0}$: & prior knowledge of ${E}[{\theta}]$ \\
$\Sigma_0$: & prior knowledge of Cov$(\theta)$
\end{tabular}
\end{center}

At each step, we assume the user's rating $y_i = \theta\cdot {x}_i+\epsilon$, where $\epsilon\sim\mathcal{N}(0,\sigma^2)$.

\subsection{Upper Confidence Bound}
At step $t+1$, we have knowledge $\mu_0,\ \Sigma_0,\ ({x}_1, y_1), \cdots, ({x}_{t}, y_t)$. The distribution 
\[\theta | [ \mu_0,\ \Sigma_0,\ ({x}_1, y_1), \cdots, ({x}_{t}, y_t) ] \sim \mathcal{N}(\mu_{t}, \Sigma_{t}) \]
where 
\begin{align}
\Sigma_{t}^{-1} = & \Sigma_0^{-1}+\frac{1}{\sigma^2}X_t^TX_t &=& \Sigma_t^{-1} + \frac{1}{\sigma^2}{x}_t{x}_t^T\\
\mu_t = & \Sigma_t\left( \Sigma_0^{-1}\mu_0 + \frac{1}{\sigma^2}X_t^Ty \right) &= &\Sigma_t\left(\Sigma_{t-1}\mu_{t-1}+\frac{1}{\sigma^2}{x}_t y_t\right)
\end{align}
where 
\begin{align*}
X_t = \left(
\begin{array}{c}
{x}_1^T\\
\vdots\\
{x}_t^T
\end{array}\right)
\end{align*}

Then, for each restaurant $r$, we suppose its feature vector is ${x}^{(r)}$. And its expected rating and variance are
\[E[{x}^{(r)}\cdot \theta] = {x}^{(r)}\cdot \mu_t,\quad Var({x}^{(r)}\cdot \theta) =({x}^{(r)})^T\Sigma_t {x}^{(r)} \]
The restaurant we will recommend at step $t+1$ is
\[r_t = \arg\max_r E[{x}^{(r)}\cdot \theta] + 1.96 \sqrt{Var({x}^{(r)}\cdot \theta)}\]




\section{Numerical Experiment}
In this simulation, we use the yelp academic dataset. The goal of this simulation is to find the favorite restaurant categories for a new user. There are 4596 restaurants in the dataset and each restaurant belongs to one or multiple categories. We first find the top twenty categories that has most restaurants, which are Pizza, Sandwiches, Food etc, and use those 20 categories as our feature. For each restaurant, if it belongs to certain category, then the corresponding element of its feature vector is 1 and 0 otherwise. So the feature vector of each restaurant is a 20 dimensional binary vector. 

For each user, we calculated his user preference vector based on his rating and the restaurants' feature vectors that he rated using ridge regression (since there are not too many ratings, ordinary linear regression doesn't work here due to singularity). Then we calculated the sample mean and the sample variance of all users' preference vector and denote them as $(\mu,\Sigma)$. We further assume that for each user's preference vector $\theta\sim N(\mu,\Sigma)$ and generate new user from this distribution.



\section{Possible Applications}

Recommender systems want to find the preference that a user would give to a subset of a finite set of items. They're widely applied to different problems. For example, they're used in Netflix where there are thousands of movies and TV episodes. The biggest challenge of these problems is that there are millions of objets and hundreds of million of users, and so it's necessary to find a model that performs well and be sufficiently fast.




\begin{thebibliography}[1]
X Zhao, P Frazier, \emph{Exploration vs. Exploitation in the Information Filtering Problem}
\end{thebibliography}

\end{document} 


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified  
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz, 
% slightly modified from the 2009 version by Kiri Wagstaff and 
% Sam Roweis's 2008 version, which is slightly modified from 
% Prasad Tadepalli's 2007 version which is a lightly 
% changed version of the previous year's version by Andrew Moore, 
% which was in turn edited from those of Kristian Kersting and 
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.  
